Использование k8s в IaaS

Егор Баяндин, технический директор S7 Travel Retail

Самолеты зеленые, теперь будут и ракеты запускать, так как купили платформу.
Black Friday коснулся и S7, началась распродажа.

История про развитие ecommerce в S7
В 18 году перешли на новую версию платформы, S7 мигрировала в другую систему бронирования, проект миграции занял около года.

Предпосылки
- до 2012 дедидки - месяцы поставки
- 2012 - приватные vmware - дни
- 2014 iaas - часы, миграция заняла пару месяцев, используют имена серверов, а не ip и прошло гладко
- 2018 - контейнеры появился k8s кластер в облаке

Сформулировали список условий (pre-condition)
stateless приложения
Service/microservices arch
Репозиторий для контейнеров
Централизованное логирование и мониторинг
Единое договоренности по сетевой структуре, появился зоопарк, перед запуском в prod договорились о общих подходах (на самом 100% не договорились, трафик заворачивают через traefik, в том числе и чтобы на лету менять конфиги)
Автоматизация поставок - желательно, можно и ручками, но для скорости

Варианты:
baremetal, на физические сервера возвращаться не хотелось
iaas, ручками настраивать k8s + api vmware, был рабочий вариант, пока не наткнулись на
CSE (ProtonOS масштабирование из коробки) - продукт от vmware, 

cse - container server extension
расширяет vcloud api для управления жизненного цикла k8s кластеров, шаблоны

Результаты - все счастливы
разработчики - не надо выпрашивать сервера
админы не надо отвлекаться от важных задач
бизнес - уменьшение ttm, экономия на ресурсах, вся инфра сейчас 300 серверов

Но это не серебряная пуля
Бд и персистетные хранилища на выд серверах
Внешний мониторинг, чтобы 
Все непросто с критичными по безопасности системами и сервисами , получилось договориться с security, с персональными данными 

Что уже удалось:
4 кластера в 2 дц - прод и дев
Система контроля продаж
Сервис предоставления мин цены
Сервис для чатов, backend (веб сокет сервер, клиенты с сайта и с моб приложения)
и + парочка систем на подходе (персональный кабинет, изначально проектировалась под k8s, и портал s7, пока монолит, но планируют распилить)

Вопросы 
Почему не baremetal?
С железом не сложилось, доп расходы - заказы, эксплуатация. В CSE низкий порог входа, за 40 минут подняли первый контейнер, после чтения документации.
Арендуют ресурсы, а не железки. Есть только одна железка - cisco router.

А что про pci-dss?
Номера карт не хранят, только данные передают, они сертиф по pci и они тоже в облаке

Примеры приложений?
Смотри выше, докладчик про них говорил.

Стек технологий для мониторинга и логов?
ELK, filebeat+logstash+elastic+kibana+grafana
Мониторинг, до k8s жили на nagios, смотрят в сторону prometheus+zabbix, решение пока не нравится, есть над чем поработать.


Kubernetes для тех кому за 30

Николай Сивко, Okmeter

Okmeter - это сервис мониторинга

Есть агент и есть серверная часть:
- 10+ сервисов на go/python
- kafka, cassandra, elastic, postresql
- bare metal + private network, так исторически сложилось и нравится, в облако ехать не хотят
- нет ci/cd
- большая нагрузка и постоянно масштабироваться (раз в два месяца)

1 попытка - На каждом сервере запущено все (cassandra, elastic, сервисы), управление в ansible

2 попытка - вынесли es на отдельные машины, нужны ресурсы

3 попытка - in memory cash метрик, нужны ресурсы

Проблемы
- сложно управлять в ansible,
- маппинг server-roles сложно, 
- сложно делать бесшовый деплой
- полный прогон почти когда не делается, можно состариться, используют теги

Управление ресурсами
Куда пристраивать новый сервис? Смотрели глазами, выбирали вручную делезки, смотрели inventory и мониторинге

И вроде как в k8s это уже есть, request+limit то что нужно
Ввязываемся, чтобы управлять ресурсами.

Требования
Отказоустойчивость и контроль
Не готовы инвестировать много времени команды, команда маленькая, полгода в рисерч долго, сделать прямо сейчас

Страх 1
k8s сложный, постоянно управляет продом, много строчек кода
Ansible простой и понятно как работает

Страх 1 На самом деле
Маппинг сервисов на ноды станет динамическим, k8s постоянно приводит к нужному стейту
Как сделать так чтобы k8s стал похож на ansible?

Страх 2 service discovery
не было, сложно, дополнительный слой (dns, etcd)
Страх 2 Компенсация
Продумали liveness/readiness пробы для проверки сервисов
Работа с отказами на балансировщиках, часто меняется список апстримов, все ретраи и таймауты должны быть продуманы. Есть доклад про балансировку, там тема раскрыта.
Graceful shutdown, логи trace id.

Страх 3 Сеть
Было 10 компьютеров и l2 и понятная адресация, а сейчас плагины которые сделают новую сеть поверх моей сети.
и трафик пойдет через iptables и kube-proxy
pod network 20+ плагинов (bgp имплементация и прочее вместо плоской сети в linux)
Меняем шило не на мыло, а на мыльный завод.

Страх 3 pod network
- не хотим дополнительную инкапсуляцию, так как сложно траблшутить
- пробовали sr-iov, работает но требования к жлезеу + VFs limit (8/64)
- flannel host-gw своя /24 на каждой ноде + стат маршруты на всех нодах

Страх 3 services
Выбрали headless services

Окей, идем в k8s, что нужно сделать
- Подготовить приложения для работы в k8s, уже были в docker
- Как будем деплоить?
- Протестировать отказы? Выдернуть мастера, днс, серверы
- Подготовить ха для production

Уже был docker, конфиги монтировались с хоста
конфиги в configmap и монтировать, но нельзя сделать reconfig
Услшали про helm, но хотелось же ресурсы, проблемы в том, что нужны immutable configmap и их нет в k8s issue 22368

Confiigs
true way - environment variables, сделали костыль в env положили в yml, пример для golang app

Без helm, используем ansible, выкатываем руками, ansible шаблонизирует спеки, потом apply

Мониторинг теперь не в терминах машины, а потребление сервисов в пределах их квот
С памятью все просто, oom киллер может придти за всеми сразу, сделали разные лимиты по памяти через несколько deployments, в итоге oom прибивает в разное время

проблема с частыми рестартами есть exp back-off (5 минут)

k8s services vs k8s headless service

selector+probes -> живые endpoints
сервис дает виртуальный ip
proxy userspace, iptables, ipvs

Картинка как работает k8s service
Есть задержка, не ясно какая и не ясно что будет если связь с apiserver оборвется

в качестве балансера envoy, научились его готовить, устраивает по фичам, деплоят как sidecar container, rolling update/rollback

Пример envoy cluster

Service mesh не используем из-за сложности, подробнее на слайдах. Ingress controller также не используем.

Идея доклада - откинут все лишнее и взять только то что нужно

HA cluster - есть много способов, есть официальная инструкция, есть kubespray, нужно разбираться как оно работает, в итоге написали свой playbook

DNS - CoreDNS, DaemonSet+host net

k8s ноды 3 мастера + n нод
на мастерах убрали noschedule taint
stateful также на эти машины в systemd и лимиты на cpu  и памяти
Резервируем ресурсы в kubelet

Картинка как выглядит pod network
На этапе когда k8s и старая инфраструктура использовали статические маршруты добавляя вручную

Итого
- Внедрили за 1 месяц, так как срезали углы
- Упрощали везде где можно, сеть и прочее
- Обратили внимание на design, обошли много граблей
- Местами костыли, подойдет не всем, но работает.
